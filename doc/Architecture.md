# Architecture

BaudEngine (Baud for short) is a distributed document database for elastic storage and flexible search.

## Data Model

Field, Entity, Edge, Space, DB

Each entity has an internal 'Unique ID' (UID) generated by the system, which is unique aross the entire system. 

Entities as documents: UID -> Fields

Edges as documents: (UIDi, UIDj) -> Fields

Field: name -> a typed value or a sorted array of values

Any field of entities or edges can be indexed and morever full-text search is a first-class citizen. 

## Overview

BaudEngine is a multi-datacenter distributed system. 

### components

master, raft replication for high availability

partitionserver (PS)

router

### software stack

* cluster management

conainer-native - baud runs on Kubernetes clusters

each DB is allocated with its own set of PS across different datacenters (zones). 

each zone has a group of routers which are shared by all the applications. 

* BaudStorage

BS is mounted to store partition data (sorted key-value files and WAL) 

### partitioning & replication

db -> entity or edge space -> partition -> slot

partition = slot id range

each partition has a Raft state machine located in three or five partitionservers of different zones, i.e., partitionservers run the 'multi-raft' protocol. 

### re-sharding

Note that all the partition data is persistent on the BaudStorage distributed filesystem - actually BaudEngine is a pure computing system seperated with storage. 

So we leverage it to do partition splitting in an easier way. 

### scalability guarantee

One Baud cluster can host one to thousands of databases; 
one DB can host billions of spaces;
one space can host unlimited number of objects;

## Master

three/five/.. BM instances form a replicated BM service, or leverage a distributed coordination service like etcd/consul to store the metadata of Baud itself. 

we currently choose the former approach. 

* e.g. Start a master via cmd shell,

host2:$ baud -cm -http-addr host2:5001 -raft-addr host2:5002 -topo http://host1:5001 -data ~/node


### data structures

* database metadata

db (name -> id)

space (name -> id): entity or edge

partition (slot id range of (source) entity uid) : entity or edge

* cluster topo metadata

master nodes

ps nodes

router nodes

### persistence

marshalled and written to the underlying key-value store

### key operations

* Create a Space

* Split a Partition

* Merge Partitions

the reverse process of split

* PS metrics reporting

* Router metrics reporting


## PS

multi-raft, a raft per partition

### Kernel - inside a partition

The storage and indexing backend for each partition consists of several B-Tree tables. 

* FieldTable

for entity partition, (UID, fieldID) -> a single or multiple packed values of the field;

for edge partition, (<UID1, UID2>, fieldID) -> ...

FieldTables are on the disk. 

* PostingListTable

foreach field, an in-memory B-Tree as the Dictionary, terms as the keys and the leaf values are the pointers to PostingLists. 

one optional implementation is as below: 

type PostingList struct {
    chunks []*PostingChunk
    numOfChunks int
    numOfPostings int
}

type PostingChunk struct {
    postingArray []byte
    capx int
    size int
}

* PositionListTable

foreach field, (docID + term) -> PositionList, in-memory

type PositionList struct {
    positions []uint32
    wdf int
}

* SynonymTable

term synonyms

on-disk store


### Key Operations


## Router

## Search

### Ranking

## Manageability

Ops Center

Dashboard

### Monitoring

cluster-level statistics

space-level info

individual nodes

GC

SlowLog

### Deployment and Configration


### Upgrade


## Applications

### document databases

### search engine

### social backend

email

messaging

blogging



