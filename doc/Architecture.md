# The Architecture of BaudEngine

BaudEngine is a distributed document database.

## Features

* the best of SQL and NoSQL in one system

* dynamic schema

* unlimited scalability

* cloud-native

* multi-model

## Data Model

Field, Object, Space, DB

* Object (Document)

OID (primary key) -> fields

OID can be specified by applications or generated by the system

* Field

Field: key -> a scalar value, an array of values, or a nested structure

Any field can be indexed and morever full-text search is a first-class citizen. 

Formally, a field is defined as (name, value, property) where property = (dataType, indexType, analyzer).

* Field Datatypes

string, numberic, date, boolen, binary

array, object

Geo-point, geo-shape

* Analysis

text -> term

* Routing

hash of the routing key

document -> partition

* Mapping

Each space has a 'mapping' to specify the field types, how to index, analyzer etc.

Usually a scalar field is defined as the primary key and a scalar field as the routing key. And they can be same.

* Dynamic Mapping

The mappings are not only defined explicitly, but can be generated automatically, i.e. you can add new fields on the insert time.

* Graph

Native support for the SPO model

Edges as a special kind of fields: predicates as keys, and an array of "space/oid" as values


## System Concepts

BaudEngine is a multi-datacenter distributed system. However, it can be run in the single-datacenter mode.  

### zone

Zones, or called cells, are the unit of physical isolation as well as admin deployment. 

### components

* Master

the global master of the entire cluster

the zone master per zone

both are based on raft replication for high availability

* Partition Server

the writer role, i.e. Writer Partition Server (WPS)

the reader role, i.e. Reader Partition Server (RPS)

* Client

the Go SDK directly talking with masters and PSes.

* Gateway Servers

MyGate - the NewSQL gateway with MySQL-compatible protocol

Router - the NoSQL gateway with ElasticSearch-compatible protocol

### software stack

* cluster management

conainer-native - BaudEngine can be run in Kubernetes, or on bare metal. 

each zone has a DCOS/Kubernetes interface to allocate PS nodes and router nodes. 

each DB is allocated with its own set of PS across different zones.

* BaudStorage

As the shared datacenter storage, BS is mounted to store partition data, which is log-structured sorted key-value files and redo-logs (WALs). 

Note BaudEngine can also run on local filesystems - actually BS is transparent to BE. 

### partitioning 

db -> space -> partition = partition key hash range

The partition count is planned according to the maximum write throughput that the space should provision. 

### replication

* cross-zone replication

Each partition has a Raft state machine located in three 'writer-role' partitionservers of different zones. Actually the writer-role partitionservers run the 'multi-raft' protocol. 

* within-zone replication

In any zone, a partition can have any number of read-only replicas, which are served by the 'Reader-Role' partitionservers reading the underlying Baudstorage files. 

### scalability

* goal

One Baud cluster can host one to thousands of databases; 
one DB can host billions of spaces;
one space can host unlimited number of objects;

* scaling up/down - resizing partitions

Moving partitions between PS nodes for load balancing is easy by leveraging the BaudStorage DCFS: stop a partition replica and restart from another partitionserver.

* scaling out/in - online re-sharding

Partition splitting & merging is implemented via filtered replication. 

However, we recommand that a space is pre-sharded and somehow over-sharded to avoid re-sharding on runtime.


### local index vs. global index

currently local index only. 


### distributed transactions across partitions

the intent-based protocol: 

1, a space for trx records with UUID as keys

2, write intents for fields


## Master

There are two tiers for the cluster topo metadata managment. 

### globalmaster

* core data structures

db and space schemas

zones

partitions -> zones

note that the globalmaster has no knowledge of nodes, neither PS nodes nor router nodes

* key operations

create DB and Spaces

split or merge a partition

### zonemaster

* core data structures

partitions -> PS nodes

* key operations

assign partitions to PS nodes

* failure detector (FD)

distributed voting of PS health

* placement driver (PD)


### implementation

based on a distributed coordination service like etcd.


## PartitionServer

there are two PS roles, i.e. two modes of running instances: 

* the writer role. participating multi-raft, a raft statemachine per partition, and logging the raft operations locally 

* the reader role. just reading from BaudStorage to serve partition read-only requests

### partition storage engine

Each partition has a storage engine for storing and indexing its objects. 

And the underlying storage engine should be log-structured so as to be persisted to the Baudstorage distributed filesystem. 

There are two pluggable storage engines: blevesearch, and kernel. 

### batch operations

multiple writes grouped into one batch within a partition

### change streaming

each individual change record contains the change type (insert/update/delete) and the pre and post-image of the fields modified. 

## Router

A zone has a group of router nodes as the service gateway for the application of the same zone. Note a router needs to interact with not only the zonemaster of its own zone but also the zonemasters of other zones. 

### query language

Router extends elasticsearch DSL: 

* Graph


## MyGate

MySQL driver --> MyGate

### data model mapping

table vs space

space = tables sharing the same partitioning key


row vs object

object fields = row fields + the field of 'tableid'


compound indexes

multiple columns form a new field


### schema management

There is a 'system' DB on BaudEngine.

### SQL parsing, planning, and executing


## Manageability

### Deployment Flexibility

* single zone or multiple zones

* the BaudStorage datacenter filesystem or local filesystems

* raft-based write replication and/or storage-shared read replication

* Kubernetes or bare metal

### Backup and Restore

provide a point-in-time snapshot of the data on a partition

### Monitoring

cluster-level statistics

space-level info

individual nodes

GC

SlowLog

### Ops Center


## Applications

products

email

messaging

blogging

knowledge graphs


